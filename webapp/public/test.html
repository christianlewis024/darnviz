<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DarnViz Extension Test</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
      margin: 0;
      padding: 20px;
      background-color: #121212;
      color: white;
    }
    
    .container {
      max-width: 800px;
      margin: 0 auto;
    }
    
    header {
      text-align: center;
      margin-bottom: 30px;
    }
    
    h1 {
      color: #00CCFF;
    }
    
    .status-panel {
      background-color: #1E1E1E;
      border-radius: 8px;
      padding: 15px;
      margin-bottom: 20px;
    }
    
    .status-panel h2 {
      margin-top: 0;
      border-bottom: 1px solid #333;
      padding-bottom: 10px;
    }
    
    .status-item {
      margin-bottom: 10px;
      display: flex;
      justify-content: space-between;
    }
    
    .status-value {
      font-weight: bold;
      color: #00CCFF;
    }
    
    .status-value.error {
      color: #FF5555;
    }
    
    .status-value.success {
      color: #55FF55;
    }
    
    .control-panel {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
    }
    
    button {
      background-color: #00CCFF;
      color: white;
      border: none;
      padding: 10px 15px;
      border-radius: 4px;
      font-weight: bold;
      cursor: pointer;
    }
    
    button:hover {
      background-color: #0099CC;
    }
    
    button:disabled {
      background-color: #555;
      cursor: not-allowed;
    }
    
    .visualizers {
      display: flex;
      gap: 20px;
      margin-bottom: 20px;
    }
    
    .visualizer {
      flex: 1;
      height: 200px;
      background-color: #1E1E1E;
      border-radius: 8px;
      position: relative;
    }
    
    .visualizer-title {
      position: absolute;
      top: 10px;
      left: 10px;
      font-size: 14px;
      opacity: 0.7;
    }
    
    canvas {
      width: 100%;
      height: 100%;
      display: block;
    }
    
    .log-panel {
      background-color: #1E1E1E;
      border-radius: 8px;
      padding: 15px;
      max-height: 200px;
      overflow: auto;
    }
    
    .log-panel h2 {
      margin-top: 0;
      border-bottom: 1px solid #333;
      padding-bottom: 10px;
    }
    
    .log-entry {
      margin-bottom: 5px;
      font-family: monospace;
      font-size: 12px;
    }
    
    .log-time {
      color: #888;
      margin-right: 10px;
    }
    
    .log-message {
      color: #CCC;
    }
    
    .log-error {
      color: #FF5555;
    }
    
    @media (max-width: 768px) {
      .visualizers {
        flex-direction: column;
      }
      
      .visualizer {
        height: 150px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>DarnViz Extension Test</h1>
      <p>This page tests the communication between the DarnViz extension and a web page.</p>
    </header>
    
    <div class="status-panel">
      <h2>Extension Status</h2>
      <div class="status-item">
        <span>Extension Detected:</span>
        <span id="extensionDetected" class="status-value">Checking...</span>
      </div>
      <div class="status-item">
        <span>Extension Version:</span>
        <span id="extensionVersion" class="status-value">-</span>
      </div>
      <div class="status-item">
        <span>Capture Status:</span>
        <span id="captureStatus" class="status-value">-</span>
      </div>
      <div class="status-item">
        <span>Audio Data:</span>
        <span id="audioDataStatus" class="status-value">-</span>
      </div>
    </div>
    
    <div class="control-panel">
      <button id="startCapture" disabled>Start Capture</button>
      <button id="stopCapture" disabled>Stop Capture</button>
      <button id="reconnect">Reconnect</button>
    </div>
    
    <div class="visualizers">
      <div class="visualizer">
        <span class="visualizer-title">Frequency Data</span>
        <canvas id="frequencyCanvas"></canvas>
      </div>
      <div class="visualizer">
        <span class="visualizer-title">Waveform</span>
        <canvas id="waveformCanvas"></canvas>
      </div>
    </div>
    
    <div class="log-panel">
      <h2>Event Log</h2>
      <div id="logContainer"></div>
    </div>
  </div>
  
  <script>
    // DOM Elements
    const extensionDetectedElement = document.getElementById('extensionDetected');
    const extensionVersionElement = document.getElementById('extensionVersion');
    const captureStatusElement = document.getElementById('captureStatus');
    const audioDataStatusElement = document.getElementById('audioDataStatus');
    const startCaptureButton = document.getElementById('startCapture');
    const stopCaptureButton = document.getElementById('stopCapture');
    const reconnectButton = document.getElementById('reconnect');
    const logContainer = document.getElementById('logContainer');
    const frequencyCanvas = document.getElementById('frequencyCanvas');
    const waveformCanvas = document.getElementById('waveformCanvas');
    
    // Canvas context setup
    const frequencyCtx = frequencyCanvas.getContext('2d');
    const waveformCtx = waveformCanvas.getContext('2d');
    
    // Resize canvases for high DPI displays
    function setupCanvas(canvas, context) {
      // Get the device pixel ratio
      const dpr = window.devicePixelRatio || 1;
      
      // Get the size of the canvas in CSS pixels
      const rect = canvas.getBoundingClientRect();
      
      // Set the canvas width and height taking into account the device pixel ratio
      canvas.width = rect.width * dpr;
      canvas.height = rect.height * dpr;
      
      // Scale the context to ensure correct drawing operations
      context.scale(dpr, dpr);
      
      // Set CSS width and height to maintain the same visible size
      canvas.style.width = rect.width + 'px';
      canvas.style.height = rect.height + 'px';
    }
    
    // Set up both canvases
    setupCanvas(frequencyCanvas, frequencyCtx);
    setupCanvas(waveformCanvas, waveformCtx);
    
    // Extension detection and state
    let extensionConnected = false;
    let isCapturing = false;
    let audioDataInterval = null;
    let lastAudioData = null;
    
    // Add an event to the log
    function logEvent(message, isError = false) {
      const now = new Date();
      const timeString = now.toLocaleTimeString();
      
      const logEntry = document.createElement('div');
      logEntry.className = 'log-entry';
      
      const timeSpan = document.createElement('span');
      timeSpan.className = 'log-time';
      timeSpan.textContent = timeString;
      
      const messageSpan = document.createElement('span');
      messageSpan.className = isError ? 'log-error' : 'log-message';
      messageSpan.textContent = message;
      
      logEntry.appendChild(timeSpan);
      logEntry.appendChild(messageSpan);
      
      logContainer.appendChild(logEntry);
      
      // Auto-scroll to bottom
      logContainer.scrollTop = logContainer.scrollHeight;
    }
    
    // Update UI based on extension connection state
    function updateExtensionStatus(connected, version = null) {
      extensionConnected = connected;
      
      if (connected) {
        extensionDetectedElement.textContent = 'Yes';
        extensionDetectedElement.className = 'status-value success';
        
        if (version) {
          extensionVersionElement.textContent = version;
        }
        
        startCaptureButton.disabled = false;
      } else {
        extensionDetectedElement.textContent = 'No';
        extensionDetectedElement.className = 'status-value error';
        extensionVersionElement.textContent = '-';
        startCaptureButton.disabled = true;
        stopCaptureButton.disabled = true;
      }
    }
    
    // Update UI based on capture state
    function updateCaptureStatus(capturing) {
      isCapturing = capturing;
      
      if (capturing) {
        captureStatusElement.textContent = 'Active';
        captureStatusElement.className = 'status-value success';
        startCaptureButton.disabled = true;
        stopCaptureButton.disabled = false;
        
        // Start requesting audio data
        startAudioDataRequests();
      } else {
        captureStatusElement.textContent = 'Inactive';
        captureStatusElement.className = 'status-value';
        startCaptureButton.disabled = !extensionConnected;
        stopCaptureButton.disabled = true;
        
        // Stop audio data requests
        stopAudioDataRequests();
      }
    }
    
    // Start requesting audio data periodically
    function startAudioDataRequests() {
      if (audioDataInterval) {
        clearInterval(audioDataInterval);
      }
      
      // Request audio data every 50ms (20fps)
      audioDataInterval = setInterval(() => {
        window.postMessage({
          type: 'DARNVIZ_REQUEST_AUDIO_DATA'
        }, '*');
      }, 50);
      
      audioDataStatusElement.textContent = 'Requesting...';
    }
    
    // Stop audio data requests
    function stopAudioDataRequests() {
      if (audioDataInterval) {
        clearInterval(audioDataInterval);
        audioDataInterval = null;
      }
      
      audioDataStatusElement.textContent = '-';
      lastAudioData = null;
      
      // Clear visualizations
      clearVisualizations();
    }
    
    // Clear visualizations
    function clearVisualizations() {
      const width = frequencyCanvas.width / window.devicePixelRatio;
      const height = frequencyCanvas.height / window.devicePixelRatio;
      
      frequencyCtx.clearRect(0, 0, width, height);
      waveformCtx.clearRect(0, 0, width, height);
    }
    
    // Draw frequency visualization
    function drawFrequencyVisualization(frequencyData) {
      const width = frequencyCanvas.width / window.devicePixelRatio;
      const height = frequencyCanvas.height / window.devicePixelRatio;
      
      frequencyCtx.clearRect(0, 0, width, height);
      
      // Gradient
      const gradient = frequencyCtx.createLinearGradient(0, 0, 0, height);
      gradient.addColorStop(0, '#00FFFF');
      gradient.addColorStop(0.5, '#0099FF');
      gradient.addColorStop(1, '#0066CC');
      
      frequencyCtx.fillStyle = gradient;
      
      // Draw bars
      const barWidth = width / frequencyData.length;
      
      for (let i = 0; i < frequencyData.length; i++) {
        const value = frequencyData[i];
        const percent = value / 255;
        const barHeight = height * percent;
        
        frequencyCtx.fillRect(
          i * barWidth,
          height - barHeight,
          barWidth - 1,
          barHeight
        );
      }
    }
    
    // Draw waveform visualization
    function drawWaveformVisualization(timeData) {
      const width = waveformCanvas.width / window.devicePixelRatio;
      const height = waveformCanvas.height / window.devicePixelRatio;
      
      waveformCtx.clearRect(0, 0, width, height);
      
      // Line style
      waveformCtx.strokeStyle = '#FF00CC';
      waveformCtx.lineWidth = 2;
      
      // Draw waveform
      waveformCtx.beginPath();
      
      const sliceWidth = width / timeData.length;
      let x = 0;
      
      for (let i = 0; i < timeData.length; i++) {
        const v = timeData[i] / 128.0;
        const y = v * height / 2;
        
        if (i === 0) {
          waveformCtx.moveTo(x, y);
        } else {
          waveformCtx.lineTo(x, y);
        }
        
        x += sliceWidth;
      }
      
      waveformCtx.lineTo(width, height / 2);
      waveformCtx.stroke();
    }
    
    // Update visualizations with new audio data
    function updateVisualizations(audioData) {
      if (!audioData) return;
      
      drawFrequencyVisualization(audioData.frequencyData);
      drawWaveformVisualization(audioData.timeData);
      
      // Update status
      audioDataStatusElement.textContent = 'Receiving';
      audioDataStatusElement.className = 'status-value success';
    }
    
    // Button click handlers
    startCaptureButton.addEventListener('click', () => {
      logEvent('Requesting audio capture...');
      
      window.postMessage({
        type: 'DARNVIZ_START_CAPTURE'
      }, '*');
    });
    
    stopCaptureButton.addEventListener('click', () => {
      logEvent('Stopping audio capture...');
      
      window.postMessage({
        type: 'DARNVIZ_STOP_CAPTURE'
      }, '*');
    });
    
    reconnectButton.addEventListener('click', () => {
      logEvent('Attempting to reconnect with extension...');
      
      // Send a "ready" message that the extension should respond to
      window.postMessage({
        type: 'DARNVIZ_WEBAPP_READY'
      }, '*');
    });
    
    // Listen for messages from the extension's content script
    window.addEventListener('message', (event) => {
      // Make sure message is from the same window
      if (event.source !== window) return;
      
      const data = event.data;
      
      if (!data || !data.type) return;
      
      // Log incoming messages for debugging (throttled to avoid spam)
      if (Date.now() % 2000 < 50) {
        console.log('Received message from extension:', data.type);
      }
      
      switch (data.type) {
        case 'DARNVIZ_EXTENSION_LOADED':
          logEvent(`Extension loaded (version ${data.version})`);
          updateExtensionStatus(true, data.version);
          break;
          
        case 'DARNVIZ_EXTENSION_CONNECTED':
          logEvent(`Extension connected (version ${data.version})`);
          updateExtensionStatus(true, data.version);
          break;
          
        case 'DARNVIZ_CAPTURE_STATUS':
          logEvent(`Capture status: ${data.isCapturing ? 'Active' : 'Inactive'}`);
          updateCaptureStatus(data.isCapturing);
          break;
          
        case 'DARNVIZ_AUDIO_DATA':
          lastAudioData = data;
          updateVisualizations(data);
          break;
          
        case 'DARNVIZ_CAPTURE_ERROR':
          logEvent(`Capture error: ${data.error}`, true);
          updateCaptureStatus(false);
          break;
          
        case 'DARNVIZ_AUDIO_DATA_ERROR':
          logEvent(`Audio data error: ${data.error}`, true);
          audioDataStatusElement.textContent = 'Error';
          audioDataStatusElement.className = 'status-value error';
          break;
          
        case 'DARNVIZ_AUDIO_PROCESSING_READY':
          logEvent('Audio processing ready');
          break;
          
        case 'DARNVIZ_AUDIO_PROCESSING_ERROR':
          logEvent(`Audio processing error: ${data.error}`, true);
          break;
      }
    });
    
    // Initial connection attempt
    logEvent('Page loaded. Checking for DarnViz extension...');
    
    // Send a "ready" message that the extension should respond to
    window.postMessage({
      type: 'DARNVIZ_WEBAPP_READY'
    }, '*');
    
    // If no response in 2 seconds, assume extension is not installed
    setTimeout(() => {
      if (!extensionConnected) {
        logEvent('Extension not detected. Please install the DarnViz extension.', true);
        updateExtensionStatus(false);
      }
    }, 2000);
    
    // Handle window resize
    window.addEventListener('resize', () => {
      // Resize canvases
      setupCanvas(frequencyCanvas, frequencyCtx);
      setupCanvas(waveformCanvas, waveformCtx);
      
      // Redraw visualizations if we have data
      if (lastAudioData) {
        updateVisualizations(lastAudioData);
      }
    });
  </script>
</body>
</html>
